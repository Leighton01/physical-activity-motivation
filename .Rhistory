mins ~ c("a1","a1")*enjoyb + guiltb + oppb + fitb + socialb + age + gender + eth
'
m2 <- '
# Mediators
enjoyb ~ age + gender + eth
guiltb ~ age + gender + eth
oppb ~ age + gender + eth
fitb ~ age + gender + eth
socialb ~ age + gender + eth
# Main outcome
mins ~ enjoyb + c(a,a)*guiltb + oppb + fitb + socialb + age + gender + eth
'
m3 <- '
# Mediators
enjoyb ~ age + gender + eth
guiltb ~ age + gender + eth
oppb ~ age + gender + eth
fitb ~ age + gender + eth
socialb ~ age + gender + eth
# Main outcome
mins ~ enjoyb + guiltb + c(a,a)*oppb + fitb + socialb + age + gender + eth
'
m4 <- '
# Mediators
enjoyb ~ age + gender + eth
guiltb ~ age + gender + eth
oppb ~ age + gender + eth
fitb ~ age + gender + eth
socialb ~ age + gender + eth
# Main outcome
mins ~ enjoyb + guiltb + oppb + c(a,a)*fitb + socialb + age + gender + eth
'
m5 <- '
# Mediators
enjoyb ~ age + gender + eth
guiltb ~ age + gender + eth
oppb ~ age + gender + eth
fitb ~ age + gender + eth
socialb ~ age + gender + eth
# Main outcome
mins ~ enjoyb + guiltb + oppb + fitb + c(a,a)*socialb + age + gender + eth
'
# Small eigenvalue close to 0, does not matter
f1 <- sem(m1, data = dallb, group = "group", meanstructure = TRUE)
f2 <- sem(m2, data = dallb, group = "group", meanstructure = TRUE)
f3 <- sem(m3, data = dallb, group = "group", meanstructure = TRUE)
f4 <- sem(m4, data = dallb, group = "group", meanstructure = TRUE)
f5 <- sem(m5, data = dallb, group = "group", meanstructure = TRUE)
# Check all models are significantly different from m0
anova(f0, f1)
anova(f0, f2)
anova(f0, f3)
anova(f0, f4)
anova(f0, f5)
# Put slope diff. in a table
params <- parameterEstimates(f0, standardized = T)
# filter
slopes <- params %>%
filter(lhs == "mins", op == "~") %>%
dplyr::select(var=rhs, group, est, se)
# filtre more
slopes.ad <- slopes %>% filter(group == 1) %>%
dplyr::select(var, est.adult = est, se.adult = se)
slopes.ch <- slopes %>% filter(group == 2) %>%
dplyr::select(var, est.youth = est, se.youth = se)
# join!
slopes.diff <- data.frame()
slopes.diff <- left_join(slopes.ch, slopes.ad, by = "var")
# calculate
slopes.diff <- slopes.diff %>%
mutate(
diff = est.youth - est.adult
# se.diff = sqrt(se.adult^2 + se.youth^2),
# z = diff / se.diff,
# p = 2 * (1 - pnorm(abs(z)))
) %>%
filter(!var %in% c("gender","eth")) %>%
dplyr::select(-se.youth, -se.adult)
slopes.diff
# Libraries ---------------------------------------------------------------
set.seed(2025)
library(tidyverse)
library(Hmisc)
library(ggplot2)
library(nnet)
library(tidyLPA)
library(poLCA)
library(poLCAExtra)
# LCA, Youths -------------------------------------------------------------
child.lik <- child.lik.back
# Predictors (motives)
child.lik.y <- (child.lik %>%
dplyr::select(-mins,-age,-gender,-eth))
child.lik.y <- as.matrix(child.lik.y %>% mutate(across(everything(), as.integer)))
# Spec formula for LCA
lca.f.child <- child.lik.y ~ gender + eth
# Run LCA with 2-7 classes
LCAE.ch <- poLCA(lca.f.child, data = child.lik, nclass = 2:7)
save(LCAE.ch, file="LCAE.ch.RData")
# load("LCAE.ch.RData")
# load(file="LCAE.ch.RData")
# bootstrapped Vuong-Lo-Mendell-Rubin likelihood ratio test
# blrt.ch <- poLCA.blrt(LCAE.ch,quick = T, nrep=10)
# save(blrt.ch,file="blrt.ch.RData")
# load("blrt.ch.RData")
# Output
ch.lca.output <- LCAE.ch$output %>% dplyr::select(nclass,llike,AIC,BIC,
Rel.Entropy,LMR,p)
ch.lca.output
# check max posterior
# for(k in 2:4){
#
#   child.lik$post <- apply(LCAE.ch$LCA[[k]]$posterior, 1, max)
#
#   child.lik$class <- LCAE.ch$LCA[[k]]$predclass
#
#   print(
#     ggplot(child.lik, aes(x = post, fill = factor(class))) +
#     geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
#     labs(x = "Max Posterior Probability", y = "Count", fill = "Class",
#          title = paste0(k+1," Classes, Youths")) +
#     theme_minimal()
#   )
#
#   print(ggplot(child.lik, aes(x = factor(class), y = post)) +
#     geom_boxplot(fill = "skyblue") +
#     labs(x = "Class", y = "Max Posterior Probability",
#          title = paste0(k+1," Classes, Youths")) +
#     theme_minimal()
#   )
# }
# Compare 3 and 4 class average posterior and class prop
post4.ch <- LCAE.ch$LCA[[3]]$posterior
class4.ch <- apply(post4.ch, 1, which.max)
class.size4.ch <- prop.table(table(class4.ch))
ave.pp4.ch <- sapply(1:ncol(post4.ch), function(k) {
inds <- which(class4.ch == k)
mean(post4.ch[inds, k])
})
post3.ch <- LCAE.ch$LCA[[2]]$posterior
class3.ch <- apply(post3.ch, 1, which.max)
class.size3.ch <- prop.table(table(class3.ch))
ave.pp3.ch <- sapply(1:ncol(post3.ch), function(k) {
inds <- which(class3.ch == k)
mean(post3.ch[inds, k])
})
# BEST CLASS decided
# 3 classes is best
lca.best.ch <- LCAE.ch$LCA[[2]]
child.lik$class <- lca.best.ch$predclass
# child.lik$post <- apply(lca.best.ch$posterior, 1, max)
# Calculate median minutes
n.classes <- 3
wmed.ch <- numeric(n.classes)
wq25.ch <- numeric(n.classes)
wq75.ch <- numeric(n.classes)
for (k in 1:n.classes) {
q <- wtd.quantile(child.lik$mins,
weights = lca.best.ch$posterior[,k],
probs = c(0.25, 0.5, 0.75))
wq25.ch[k] <- q[1]
wmed.ch[k] <- q[2]
wq75.ch[k] <- q[3]
}
# Regressions
child.lik$age <- child.lik.back$age
child.lik$class <- relevel(factor(child.lik$class), ref = "1")
child.lik$age <- relevel(factor(child.lik$age), ref = "1")
fit.ch <- multinom(class ~ age,
data = child.lik %>%
dplyr::select(-post,-mins))
colnames(child.lik)
fit.ch <- multinom(class ~ age,
data = child.lik %>%
dplyr::select(-mins))
fit.ch <- multinom(class ~ age,
data = child.lik)
fit.ch0 <- multinom(class ~ age,
data = child.lik)
fit.ch <- multinom(class ~ age,
data = child.lik %>%
dplyr::select(-mins))
# odds ratio
or.ch <- exp(coef(fit.ch))
or.ch
# odds ratio
or.ch <- exp(coef(fit.ch0))
or.ch
# Regressions
child.lik$age <- child.lik.back$age
child.lik$class <- relevel(factor(child.lik$class), ref = "1")
child.lik$age <- relevel(factor(child.lik$age), ref = "1")
fit.ch <- multinom(class ~ age,
data = child.lik)
# odds ratio
or.ch <- exp(coef(fit.ch))
or.ch
# Compare 3 and 4 class average posterior and class prop
post4.ch <- LCAE.ch$LCA[[3]]$posterior
class4.ch <- apply(post4.ch, 1, which.max)
class.size4.ch <- prop.table(table(class4.ch))
ave.pp4.ch <- sapply(1:ncol(post4.ch), function(k) {
inds <- which(class4.ch == k)
mean(post4.ch[inds, k])
})
ave.pp4.ch
post3.ch <- LCAE.ch$LCA[[2]]$posterior
class3.ch <- apply(post3.ch, 1, which.max)
class.size3.ch <- prop.table(table(class3.ch))
ave.pp3.ch <- sapply(1:ncol(post3.ch), function(k) {
inds <- which(class3.ch == k)
mean(post3.ch[inds, k])
})
ave.pp3.ch
# Calculate median minutes
n.classes <- 3
wmed.ch <- numeric(n.classes)
wq25.ch <- numeric(n.classes)
wq75.ch <- numeric(n.classes)
for (k in 1:n.classes) {
q <- wtd.quantile(child.lik$mins,
weights = lca.best.ch$posterior[,k],
probs = c(0.25, 0.5, 0.75))
wq25.ch[k] <- q[1]
wmed.ch[k] <- q[2]
wq75.ch[k] <- q[3]
}
# Regressions
child.lik$age <- child.lik.back$age
child.lik$class <- relevel(factor(child.lik$class), ref = "1")
child.lik$age <- relevel(factor(child.lik$age), ref = "1")
fit.ch <- multinom(class ~ age,
data = child.lik)
# odds ratio
or.ch <- exp(coef(fit.ch))
or.ch
sum.fit.ch <- summary(fit.ch)
se <- sum.fit.ch$standard.errors
# Coefficients
coefs.ch <- coef(fit.ch)
# 95% CI for odds ratios
ci.l.ch <- exp(coefs.ch - 1.96 * se)
ci.u.ch <- exp(coefs.ch + 1.96 * se)
# Odds ratios themselves
or <- exp(coefs.ch)
# Combine into a table
or.ci.ch <- data.frame(
CI.lower = round(ci.l.ch, 3),
CI.upper = round(ci.u.ch, 3)
)
colnames(or.ci.ch) <- c("Intercept.L", "Age2.L", "Age3.L", "Age4.L",
"Age5.L","Age6.L","Intercept.U","Age2.U", "Age3.U", "Age4.U",
"Age5.U","Age6.U")
or.ci.ch
tb.byage.ch <- child.lik %>%
count(age, class) %>%
pivot_wider(names_from = class, values_from = n, values_fill = 0)
tb.byage.ch
# elbow plot
gg.elbow.ch <- ggplot(ch.lca.output, aes(x = nclass)) +
geom_line(aes(y = BIC), color = "blue") +
geom_point(aes(y = BIC), color = "blue") +
geom_line(aes(y = AIC), color = "red") +
geom_point(aes(y = AIC), color = "red") +
labs(y = "Information Criterion", x = "Number of Classes",
title = "Elbow Plot, Youths",
caption = "Blue = BIC, Red = AIC") +
theme_clean()
gg.elbow.ch
gg.llik.ch <- ggplot(ch.lca.output, aes(x = nclass)) +
geom_line(aes(y = llike), color = "blue") +
geom_point(aes(y = llike), color = "blue") +
labs(y = "Log-Likelihood", x = "Number of Classes",
title = "Log-Likelihood, Youths") +
theme_clean()
gg.llik.ch
tb.class3.ch <- data.frame(
Class = 1:ncol(post3.ch),
Proportion = as.numeric(class.size3.ch),
Avg_Posterior = round(ave.pp3.ch, 3)
)
tb.class3.ch
mins.child
# Weighted minutes, youths
mins.child <- data.frame(
Class = 1:n.classes,
Weighted.Median = wmed.ch,
Weighted.Q25 = wq25.ch,
Weighted.Q75 = wq75.ch
)
mins.child
gg.mins.ch <- ggplot(mins.child, aes(x = factor(Class), y = Weighted.Median)) +
geom_point(size = 3, color = "blue") +                 # median as a point
geom_errorbar(aes(ymin = Weighted.Q25, ymax = Weighted.Q75),
width = 0.2, color = "darkblue") +      # IQR as error bars
labs(x = "Class", y = "Minutes (Weighted Median ± IQR)",
title = "Weighted Median and IQR per Class") +
theme_clean()
gg.mins.ch
gg.med.ch <- ggplot(mins.child, aes(x = Class, y = Weighted.Median)) +
geom_col() +
labs(x = "Latent Class", y = "Probability-Weighted Median Minutes")
gg.med.ch
# Predictor plot
plot(LCAE.ch, nclass = 2)
# Appendix
or.ci.ch
# Bootstrap Vuong-Lo-Mendell-Rubin Likelihood Ratio Test
or.ch
adult.lik <- adult.lik.back
# Predictors (motives)
adult.lik.y <- as.matrix(adult.lik %>%
dplyr::select(-mins,-age,-gender,-eth,-edu))
# Spec formula for LCA
lca.f.adult <- adult.lik.y ~ gender + eth + edu
LCAE.ad <- poLCA(lca.f.adult, data = adult.lik, nclass = 2:7)
# LCAE.ad <- poLCA(lca.f.adult, data = adult.lik, nclass = 2:7)
save(LCAE.ad, file="LCAE.ad.RData")
# Take relevant stats
ad.lca.output <- LCAE.ad$output %>% dplyr::select(nclass,llike,AIC,BIC,
Rel.Entropy,LMR,p)
ad.lca.output
ch.lca.output
# BEST CLASS decided
# 3 classes is best
lca.best.ad <- LCAE.ad$LCA[[2]]
post5.ad <- LCAE.ad$LCA[[4]]$posterior
class5.ad <- apply(post5.ad, 1, which.max)
class.size5.ad <- prop.table(table(class5.ad))
ave.pp5.ad <- sapply(1:ncol(post5.ad), function(k) {
inds <- which(class5.ad == k)
mean(post5.ad[inds, k])
})
ave.pp5.ad
post4.ad <- LCAE.ad$LCA[[3]]$posterior
class4.ad <- apply(post4.ad, 1, which.max)
class.size4.ad <- prop.table(table(class4.ad))
ave.pp4.ad <- sapply(1:ncol(post4.ad), function(k) {
inds <- which(class4.ad == k)
mean(post4.ad[inds, k])
})
ave.pp4.ad
post3.ad <- LCAE.ad$LCA[[2]]$posterior
class3.ad <- apply(post3.ad, 1, which.max)
class.size3.ad <- prop.table(table(class3.ad))
ave.pp3.ad <- sapply(1:ncol(post3.ad), function(k) {
inds <- which(class3.ad == k)
mean(post3.ad[inds, k])
})
ave.pp3.ad
# BEST CLASS decided
# 3 classes is best
lca.best.ad <- LCAE.ad$LCA[[2]]
adult.lik$class <- lca.best.ad$predclass
adult.lik$post <- apply(lca.best.ad$posterior, 1, max)
# Calculate median minutes
n.classes <- 3
wmed.ad <- numeric(n.classes)
wq25.ad <- numeric(n.classes)
wq75.ad <- numeric(n.classes)
for (k in 1:n.classes) {
q <- wtd.quantile(adult.lik$mins,
weights = lca.best.ad$posterior[,k],
probs = c(0.25, 0.5, 0.75))
wq25.ad[k] <- q[1]
wmed.ad[k] <- q[2]
wq75.ad[k] <- q[3]
}
# Regressions
adult.lik$age <- adult.lik.back$age
adult.lik$class <- relevel(factor(adult.lik$class), ref = "1")
adult.lik$age <- relevel(factor(adult.lik$age), ref = "1")
fit.ad <- multinom(class ~ age,
data = adult.lik)
# odds ratio
or.ad <- exp(coef(fit.ad))
or.ad
sum.fit.ad <- summary(fit.ad)
se.ad <- sum.fit.ad$standard.errors
# Coefficients
coefs.ad <- coef(fit.ad)
# 95% CI for odds ratios
ci.l.ad <- exp(coefs.ad - 1.96 * se.ad)
ci.u.ad <- exp(coefs.ad + 1.96 * se.ad)
# Combine into a table
or.ci.ad <- data.frame(
CI.lower = round(ci.l.ad, 3),
CI.upper = round(ci.u.ad, 3)
)
colnames(or.ci.ad) <- c("Intercept.L", "Age2.L", "Age3.L", "Age4.L",
"Age5.L","Age6.L","Intercept.U","Age2.U", "Age3.U", "Age4.U",
"Age5.U","Age6.U")
tb.byage.ad <- adult.lik %>%
count(age, class) %>%
pivot_wider(names_from = class, values_from = n, values_fill = 0)
tb.byage.ad
# elbow plot
gg.elbow.ad <- ggplot(ad.lca.output, aes(x = nclass)) +
geom_line(aes(y = BIC), color = "blue") +
geom_point(aes(y = BIC), color = "blue") +
geom_line(aes(y = AIC), color = "red") +
geom_point(aes(y = AIC), color = "red") +
labs(y = "Information Criterion", x = "Number of Classes",
title = "Elbow Plot, Adults",
caption = "Blue = BIC, Red = AIC") +
theme_clean()
gg.elbow.ad
gg.llik.ad <- ggplot(ad.lca.output, aes(x = nclass)) +
geom_line(aes(y = llike), color = "blue") +
geom_point(aes(y = llike), color = "blue") +
labs(y = "Log-Likelihood", x = "Number of Classes",
title = "Log-Likelihood, Adults") +
theme_clean()
gg.llik.ad
tb.class3.ad <- data.frame(
Class = 1:ncol(post3.ad),
Proportion = as.numeric(class.size3.ad),
Avg_Posterior = round(ave.pp3.ad, 3)
)
tb.class3.ad
mins.adult <- data.frame(
Class = 1:n.classes,
Weighted.Median = wmed.ad,
Weighted.Q25 = wq25.ad,
Weighted.Q75 = wq75.ad
)
mins.adult
gg.mins.ad <- ggplot(mins.adult, aes(x = factor(Class), y = Weighted.Median)) +
geom_point(size = 3, color = "blue") +                 # median as a point
geom_errorbar(aes(ymin = Weighted.Q25, ymax = Weighted.Q75),
width = 0.2, color = "darkblue") +      # IQR as error bars
labs(x = "Class", y = "Minutes (Weighted Median ± IQR)",
title = "Weighted Median and IQR per Class") +
theme_clean()
gg.mins.ad
gg.mins.ch
# Predictor plot
plot(LCAE.ad, nclass = 2)
# Bootstrap Vuong-Lo-Mendell-Rubin Likelihood Ratio Test
# 100 reps
# blrt.ad
or.ad
or.ci.ad
# Include actual coeffs in appendix
lca.best.ad$probs
tb.byage.ad
gg.byage.ad <- adult.lik %>%
dplyr::count(age, class) %>%
group_by(age) %>%
mutate(prop = n / sum(n)) %>%
ggplot(aes(x = factor(age), y = prop, fill = factor(class))) +
geom_col() +
labs(x = "Age group", y = "Proportion", fill = "Class") +
scale_y_continuous(labels = scales::percent_format()) +
theme_clean()
gg.byage.ad
gg.byage.ch
vars.ad <- setdiff(names(adult.lik), c("age","mins","post","class",
"gender","eth","edu"))
vars.ad
adult.lik_long <- adult.lik %>%
pivot_longer(cols = all_of(vars.ad), names_to = "variable", values_to = "score") %>%
count(age, variable, score) %>%
group_by(age, variable) %>%
mutate(prop = n / sum(n))
gg.vars.ad <- ggplot(adult.lik_long, aes(x = factor(age), y = prop, fill = factor(score))) +
geom_col() +
facet_wrap(~variable, nrow = 3, ncol = 3) +
labs(x = "Age group", y = "Proportion", fill = "Score") +
scale_y_continuous(labels = percent_format()) +
theme_clean() +
theme(legend.position = "bottom")
set.seed(2025)
library(tidyverse)
library(ggplot2)
library(poLCA)
library(poLCAExtra)
library(scales)
library(ggthemes)
gg.vars.ad <- ggplot(adult.lik_long, aes(x = factor(age), y = prop, fill = factor(score))) +
geom_col() +
facet_wrap(~variable, nrow = 3, ncol = 3) +
labs(x = "Age group", y = "Proportion", fill = "Score") +
scale_y_continuous(labels = percent_format()) +
theme_clean() +
theme(legend.position = "bottom")
gg.vars.ad
tb.byage.ch
gg.byage.ch <- child.lik %>%
dplyr::count(age, class) %>%
group_by(age) %>%
mutate(prop = n / sum(n)) %>%
ggplot(aes(x = factor(age), y = prop, fill = factor(class))) +
geom_col() +
labs(x = "Age group", y = "Proportion", fill = "Class") +
scale_y_continuous(labels = scales::percent_format()) +
theme_clean()
gg.byage.ch
vars.ch <- setdiff(names(child.lik), c("age","mins","post","class",
"gender","eth","edu"))
child.lik_long <- child.lik %>%
pivot_longer(cols = all_of(vars.ch), names_to = "variable", values_to = "score") %>%
count(age, variable, score) %>%
group_by(age, variable) %>%
mutate(prop = n / sum(n))
gg.vars.ch <- ggplot(child.lik_long, aes(x = factor(age), y = prop, fill = factor(score))) +
geom_col() +
facet_wrap(~variable, nrow = 3, ncol = 3) +
labs(x = "Age group", y = "Proportion", fill = "Score") +
scale_y_continuous(labels = percent_format()) +
theme_clean() +
theme(legend.position = "bottom")
