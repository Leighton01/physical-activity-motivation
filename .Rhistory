eth=eth2,
mins=mins_modplus_outschool_Week_ALL
) %>%
filter(dsbl == 2,
gender %in% c(1,2),
eth %in% c(1,2),
mins > -1,
if_all(c(enjoy,social,fit,guilt,opp,know,try,conf,easy,more),
~ .x > -1 & .x < 5)) %>%
mutate(
mins = ifelse(mins > 1680, 1680, mins),
across(c(conf,easy,enjoy,fit,know,more,opp,try),
~ case_when(.x==4~3L, TRUE ~ as.integer(.x)))
) %>%
dplyr::select(-dsbl)
adult.lik <- adult.var %>%
mutate(mins=DUR_HVY_CAPPED_SPORTCOUNT_A01+DUR_MOD_CAPPED_SPORTCOUNT_A01) %>%
# 1=strong agree, 5=strong disagree
dplyr::select(enjoy=Motiva_POP,
social=motivex2c,
fit=motivex2a,
guilt=motivc_POP,
opp=READYOP1_POP,
imp=motivb_POP,
dis=motivd_POP, #disappoint
abil=READYAB1_POP, #ability
relx=motivex2b,
chal=motivex2d,
dsbl=Disab2_POP,
gender=Gend3,
age=Age5_2,
eth=Eth2,
mins
) %>%
filter(dsbl==2,
if_all(c(gender,eth), ~ .x %in% c(1,2)),
if_all(everything(), ~ .x > -1),
) %>%
mutate(dis = 6 - dis,
across(c(abil,chal,enjoy,fit,guilt,imp,opp,relx,dis),
~ case_when(.x==5~4L, TRUE ~ as.integer(.x)))
) %>%
dplyr::select(-dsbl)
adult.lik.back <- adult.lik
library(BayesLCA)
# Fit K-1 and K class Bayesian LCA models
fit_Km1 <- adult.lik %>% dplyr::select(-mins) %>%
blca.em(, nclass = 3, nrep = 10)
# Fit K-1 and K class Bayesian LCA models
fit_Km1 <- adult.lik %>% dplyr::select(-mins) %>%
blca.em(nclass = 3, nrep = 10)
d <- adult.lik %>% dplyr::select(-mins)
# Fit K-1 and K class Bayesian LCA models
fit_Km1 <- blca.em(d,nclass = 3, nrep = 10)
?blca.em
# Fit K-1 and K class Bayesian LCA models
fit_Km1 <- blca.em(d, 3)
mod_null <- poLCA.adult[[3]]$probs
mod_alt <- poLCA.adult[[5]]$probs
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
alt_classes
mod_null <- poLCA.adult[[3]]
mod_alt <- poLCA.adult[[5]]
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
mod_null <- poLCA.adult[[3]]
mod_alt <- poLCA.adult[[4]]
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
mod_null <- poLCA.adult[[5]]
mod_alt <- poLCA.adult[[6]]
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
mod_null <- poLCA.adult[[6]]
mod_alt <- poLCA.adult[[7]]
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
table(adult.like$age)
table(adult.lik$age)
lca.f.adult
# try without age
lca.f.adult.na <- as.matrix(adult.lik %>% dplyr::select(-mins,-age)) ~ 1
poLCA.ad.na <- list()
?poLCA
for(k in 3:5){
poLCA.ad.na[[k]] <- poLCA(lca.f.adult.na, data = adult.lik,
nclass = k,
maxiter = 5000,
nrep = 10,          # multiple random starts
na.rm = TRUE,       # not needed if NAs already removed
verbose = TRUE)
}
# 3, 5, or 6
lca.best.ad <- poLCA.ad.na[[5]]
# posterior prob
max.prob.ad <- apply(lca.best.ad$posterior, 1, max)
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# check each class prob
adult.lik$max_post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = max_post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = max_post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
poLCA.ad.na[[5]]$probs
# 3, 5, or 6
lca.best.ad <- poLCA.ad.na[[3]]
# posterior prob
max.prob.ad <- apply(lca.best.ad$posterior, 1, max)
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# check each class prob
adult.lik$max_post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = max_post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = max_post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
# 3, 5, or 6
lca.best.ad <- poLCA.ad.na[[4]]
# posterior prob
max.prob.ad <- apply(lca.best.ad$posterior, 1, max)
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# check each class prob
adult.lik$max_post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = max_post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = max_post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
poLCA.ad.na[[5]]
poLCA.ad.na[[5]]$probs
poLCA.ad[[5]]$probs
poLCA.adult[[5]]$probs
library(nnet)
# 3, 5, or 6
lca.best.ad <- poLCA.ad.na[[3]]
# posterior prob
max.prob.ad <- apply(lca.best.ad$posterior, 1, max)
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# check each class prob
adult.lik$max_post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = max_post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = max_post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
# interpret
poLCA.adult[[3]]$probs
# poLCA.adult[[4]]$probs
poLCA.adult[[5]]$probs
library(BayesLCA)
d <- adult.lik %>% dplyr::select(-mins)
# Fit K-1 and K class Bayesian LCA models
fit_Km1 <- blca.em(d, 3)
mins.adult
ggplot(mins.adult, aes(x = Class, y = Mean.log)) +
geom_col() +
labs(x = "Latent Class", y = "Probability-weighted mean minutes")
mod_null <- poLCA.adult[[6]]
mod_alt <- poLCA.adult[[7]]
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
colnames(child.lik)
# Suppose df contains your predictors and you add class membership:
df <- child.lik %>%
mutate(Class = factor(poLCA.ad.na[[3]]$predclass))  # modal assignment as factor
colnames(adult.lik)
# Suppose df contains your predictors and you add class membership:
df <- adult.lik %>% select(-max_post,mins)
# Suppose df contains your predictors and you add class membership:
df <- adult.lik %>% dplyr::select(-max_post,mins)
# Example: AgeBand is coded as 1–17, or you could use midpoints
# Fit multinomial logistic regression
fit <- multinom(Class ~ age, data = df)
# Example: AgeBand is coded as 1–17, or you could use midpoints
# Fit multinomial logistic regression
fit <- multinom(class ~ age, data = df)
# Model summary
summary(fit)
# Likelihood ratio test for overall age effect
anova(fit, test = "Chisq")
# Odds ratios for easier interpretation
exp(coef(fit))
table(adult.lik$age)
table(adult.var$Age3)
table(adult.var$AgeTGC)
table(adult.var$Age4)
table(adult.var$Age5)
table(adult.var$Age5_2)
adult.lik <- adult.var %>%
mutate(mins=DUR_HVY_CAPPED_SPORTCOUNT_A01+DUR_MOD_CAPPED_SPORTCOUNT_A01) %>%
# 1=strong agree, 5=strong disagree
dplyr::select(enjoy=Motiva_POP,
social=motivex2c,
fit=motivex2a,
guilt=motivc_POP,
opp=READYOP1_POP,
imp=motivb_POP,
dis=motivd_POP, #disappoint
abil=READYAB1_POP, #ability
relx=motivex2b,
chal=motivex2d,
dsbl=Disab2_POP,
gender=Gend3,
age=AgeTGC,
eth=Eth2,
mins
) %>%
filter(dsbl==2,
if_all(c(gender,eth), ~ .x %in% c(1,2)),
if_all(everything(), ~ .x > -1),
) %>%
mutate(dis = 6 - dis,
across(c(abil,chal,enjoy,fit,guilt,imp,opp,relx,dis),
~ case_when(.x==5~4L, TRUE ~ as.integer(.x)))
) %>%
dplyr::select(-dsbl)
adult.lik.back <- adult.lik
lca.f.adult <- as.matrix(adult.lik %>% dplyr::select(-mins)) ~ 1
# run 2-7 classes
poLCA.adult <- list()
adult.lik <- adult.lik.back
adult.lik <- adult.lik %>% dplyr::select(-mins,-age,-gender,-eth)
lca.f.adult <- as.matrix(adult.lik) ~ 1
# run 2-7 classes
poLCA.adult <- list()
for(k in 1:7){
poLCA.adult[[k]] <- poLCA(lca.f.adult, data = adult.lik,
nclass = k,
maxiter = 5000,
nrep = 10,          # multiple random starts
na.rm = TRUE,       # not needed if NAs already removed
verbose = TRUE)
}
save(poLCA.adult, file="poLCA.adult.RData")
lca.stats.adult <- data.frame(
Classes = 1:7,
BIC = sapply(poLCA.adult[2:7], function(x) x$bic),
AIC = sapply(poLCA.adult[2:7], function(x) x$aic)
)
lca.stats.adult <- data.frame(
Classes = 1:7,
BIC = sapply(poLCA.adult[1:7], function(x) x$bic),
AIC = sapply(poLCA.adult[1:7], function(x) x$aic)
)
# elbow plot
ggplot(lca.stats.adult, aes(x = Classes)) +
geom_line(aes(y = BIC), color = "blue") +
geom_point(aes(y = BIC), color = "blue") +
geom_line(aes(y = AIC), color = "red") +
geom_point(aes(y = AIC), color = "red") +
labs(y = "Information Criterion", x = "Number of Classes",
title = "Elbow Plot for poLCA Model Selection",
caption = "Blue = BIC, Red = AIC") +
theme_minimal()
# INDIVIDUAL CLASSES
# 3, 5, or 6
lca.best.ad <- poLCA.ad[[3]]
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# INDIVIDUAL CLASSES
# 3, 5, or 6
lca.best.ad <- poLCA.adult[[3]]
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check each class prob
adult.lik$post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
# interpret
poLCA.adult[[3]]$probs
# Weighted means
adult.lik$mins <- adult.lik.back$mins
adult.lik$gender <- adult.lik.back$gender
adult.lik$eth <- adult.lik.back$eth
adult.lik$mins.log <- log(adult.lik$mins+1)
# probability weighted means
wmeans.adult <- colSums(post.ad * adult.lik$mins) / colSums(post.ad)
wmeans.log.adult <- colSums(post.ad * adult.lik$mins.log) / colSums(post.ad)
wsd.adult <- sapply(1:ncol(post.ad), function(k) {
sqrt( sum(post.ad[,k] * (adult.lik$mins - wmeans.adult[k])^2)
/ sum(post.ad[,k]) )
})
wsd.log.adult <- sapply(1:ncol(post.ad), function(k) {
sqrt( sum(post.ad[,k] * (adult.lik$mins.log - wmeans.log.adult[k])^2)
/ sum(post.ad[,k]) )
})
mins.adult <- data.frame(
Class = factor(1:ncol(post.ad)),
Mean = wmeans.adult,
Mean.log= exp(wmeans.log.adult)-1,
SD =wsd.adult,
SD.log = wsd.log.adult,
SD.low = exp(wmeans.log.adult - wsd.log.adult) - 1,
SD.up = exp(wmeans.log.adult + wsd.log.adult) - 1
)
mins.adult
ggplot(mins.adult, aes(x = Class, y = Mean.log)) +
geom_col() +
labs(x = "Latent Class", y = "Probability-weighted mean minutes")
mod_null <- poLCA.adult[[6]]
mod_alt <- poLCA.adult[[7]]
# store values baseline model
n <- mod_null$Nobs #number of observations (should be equal in both models)
null_ll <- mod_null$llik #log-likelihood
null_param <- mod_null$npar # number of parameters
null_classes <- length(mod_null$P) # number of classes
# Store values alternative model
alt_ll <- mod_alt$llik #log-likelihood
alt_param <- mod_alt$npar # number of parameters
alt_classes <- length(mod_alt$P) # number of classes
# use calc_lrt from tidyLPA package
calc_lrt(n, null_ll, null_param, null_classes, alt_ll, alt_param, alt_classes)
# AGE
fit.ad.age <- multinom(class ~ age,
data = adult.lik %>% dplyr::select(-post,-mins,-eth,-gender))
summary(fit.ad.age)
# Odds ratios for easier interpretation
exp(coef(fit.ad.age))
# AGE
fit.ad.age <- multinom(class ~ age,
data = adult.lik %>% dplyr::select(-post,-mins,-eth,-gender))
# Part II Adults Regression --------------------------------------------------------------
adult.lik$age <- adult.lik.back$age
# AGE
fit.ad.age <- multinom(class ~ age,
data = adult.lik %>% dplyr::select(-post,-mins,-eth,-gender))
summary(fit.ad.age)
# Odds ratios for easier interpretation
exp(coef(fit.ad.age))
# ETHNICITY
fit.ad.eth <- multinom(class ~ eth,
data = adult.lik %>% dplyr::select(-post,-mins,-age,-gender))
summary(fit.ad.eth)
# Odds ratios for easier interpretation
exp(coef(fit.ad.eth))
# GENDER
fit.ad.gender <- multinom(class ~ gender,
data = adult.lik %>% dplyr::select(-post,-mins,-eth,-age))
summary(fit.ad.gender)
# Odds ratios for easier interpretation
exp(coef(fit.ad.gender))
# INDIVIDUAL CLASSES
# 3, 5, or 6
lca.best.ad <- poLCA.adult[[4]]
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check each class prob
adult.lik$post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
# INDIVIDUAL CLASSES
# 3, 5, or 6
lca.best.ad <- poLCA.adult[[5]]
# check class size (>0.5 per)
adult.lik$class <- lca.best.ad$predclass
# table(adult.lik$class)  # modal assignment
prop.table(table(adult.lik$class))
# entropy, <0.8 good, higher != better
post.ad <- lca.best.ad$posterior
N <- nrow(post.ad)
C <- ncol(post.ad)
entro.ad <- 1 + (1/(N*log(C))) * sum(post.ad * log(post.ad))
entro.ad  # ranges 0–1, higher = better separation
# check each class prob
adult.lik$post <- apply(lca.best.ad$posterior, 1, max)
ggplot(adult.lik, aes(x = post, fill = factor(class))) +
geom_histogram(binwidth = 0.05, alpha = 0.7, position = "identity") +
labs(x = "Max Posterior Probability", y = "Count", fill = "Class") +
theme_minimal()
# boxplot per class
ggplot(adult.lik, aes(x = factor(class), y = post)) +
geom_boxplot(fill = "skyblue") +
labs(x = "Class", y = "Max Posterior Probability") +
theme_minimal()
